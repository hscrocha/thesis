% !TEX root = main.tex

\section{Problem statement}\label{sec:problem-statement}
\henrique{To me, a problem statement section should appear as earlier as possible in the thesis. It can even be a subsection of the introduction. }
% Research Question or Problem Statement

% Engineering theses tend to refer to a "problem" to be solved where other disciplines talk in terms of a "question" to be answered. In either case, this section has three main parts:

% 1. a concise statement of the question that your thesis tackles
% 2. justification, by direct reference to the literature review, that your question is previously unanswered
% 3. discussion of why it is worthwhile to answer this question.

% Item 2 above is where you analyze the information which you presented in Section 3. For example, maybe your problem is to "develop a Zylon algorithm capable of handling very large scale problems in reasonable time" (you would further describe what you mean by "large scale" and "reasonable time" in the problem statement). Now in your analysis of the state of the art you would show how each class of current approaches fails (i.e. can handle only small problems, or takes too much time). In the last part of this section you would explain why having a large-scale fast Zylon algorithm is useful; e.g., by describing applications where it can be used.

% Since this is one of the sections that the readers are definitely looking for, highlight it by using the word "problem" or "question" in the title: e.g. "Research Question" or "Problem Statement", or maybe something more specific such as "The Large-Scale Zylon Algorithm Problem." 

Improving the output of static analysis is dependent on a particular codebase and the people who produce it. Different organizations can have different priorities and expectations on code quality. Also developers or teams might be more interested on a particular subset of alerts (or the context on which the alerts appear).

Given an industrial codebase, the goal is to explore if these automatic techniques are useful, which produces the best results, and if an ensemble technique provides extra benefits. The starting point is the version control history of the project. By extracting information about the past versions, an attempt can be made to learn which SA alerts are more important and can be prioritized in the future. In contrast to open source project where you can test the approaches only on those project that have a sufficient amount of data, in an industrial codebase you have to make the most of the data you can extract. This thesis examines which ML techniques can be used to deal with highly imbalanced or noisy data.

Two main approaches are explored: detecting actionable alerts (alerts deemed useful by the developers) and alerts that aid in detecting bugs. These approaches are complementary because the sets of alerts are not necessarily equal, thus they are a good candidate for a combination.

The research questions can be formulated as follows:
\begin{itemize}
    \item R0: Can we apply SA ranking techniques in an industrial environment with limited amount of data (abandoned because of high false positives)?
    \item R1: Can we combine SA ranking techniques to achieve better results?
    \item R2: Do pre-processing techniques provide a significant performance benefit?
\end{itemize}

This research is important because it quantitatively examines if the version history of a project combined with machine learning techniques can be used to effectively improve the output of SA tools. By doing so, we can examine the real utility of this approach in practice and identify which techniques are more effective. It is also relevant to see if these approaches produce meaningful results in the case of limited amount of data. We can also observe the impact in performance by testing different ML techniques to reduce noise and balance the dataset (under and oversampling). 

Based on the literature review, few papers make direct comparisons between different methods on a common experiment baseline \cite{comparative_heckman, compare_framework}. Also, they mainly focus on open source Java systems with an adequate amount of data. Kim et al. \cite{noise_defect} research the impact of noisy data and propose a solution . Regarding ensemble techniques, there have been approaches where multiple SA tools are combined, or where each alert types is handled by its own classifier. In contrast, we focus on C++ code and compare different preprocessing techniques. Also, we try an ensemble approach with two different methods of ranking SA alerts.
